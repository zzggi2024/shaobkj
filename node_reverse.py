import json
import numpy as np
import torch
from PIL import Image
import io
import base64
import traceback

from .shaobkj_shared import (
    build_submit_timeout,
    create_requests_session,
    disable_insecure_request_warnings,
    get_config_value,
    post_json_with_retry,
    resize_pil_long_side,
)
from comfy.utils import ProgressBar


class Shaobkj_Reverse_Node:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(s):
        api_key_default = get_config_value("API_KEY", "SHAOBKJ_API_KEY", "")
        return {
            "required": {
                "ç³»ç»Ÿæç¤ºè¯": ("STRING", {"multiline": True, "default": ""}),
                "éœ€æ±‚æç¤ºè¯": ("STRING", {"multiline": True, "default": "Describe this content in detail to recreate it as a prompt."}),
                "APIå¯†é’¥": ("STRING", {"default": api_key_default, "multiline": False}),
                "APIåœ°å€": ("STRING", {"default": "https://yhmx.work", "multiline": False}),
                "æ¨¡å‹åç§°": (["gemini-2.5-flash", "gemini-1.5-pro", "gemini-1.5-flash"], {"default": "gemini-2.5-flash"}),
                "ä½¿ç”¨ç³»ç»Ÿä»£ç†": ("BOOLEAN", {"default": False}),
                "é•¿è¾¹è®¾ç½®": (["1024", "1280", "1536"], {"default": "1280"}),
                "ç­‰å¾…æ—¶é—´": ("INT", {"default": 0, "min": 0, "max": 1000000, "tooltip": "è½®è¯¢ç­‰å¾…æ—¶é—´(ç§’)ï¼Œ0ä¸ºæ— é™ç­‰å¾…"}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
                "è°·æ­Œæœç´¢": ("BOOLEAN", {"default": False}),
                "APIç”³è¯·åœ°å€": ("STRING", {"default": "https://yhmx.work/login?expired=true", "multiline": False}),
            },
            "optional": {
                "image_1": ("IMAGE",),
                "image_2": ("IMAGE",),
            },
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("æç¤ºè¯", "APIå“åº”")
    FUNCTION = "inference"
    CATEGORY = "ğŸ¤–shaobkj-APIbox"

    def inference(self, APIå¯†é’¥, APIåœ°å€, æ¨¡å‹åç§°, ç³»ç»Ÿæç¤ºè¯, éœ€æ±‚æç¤ºè¯, ä½¿ç”¨ç³»ç»Ÿä»£ç†, é•¿è¾¹è®¾ç½®, ç­‰å¾…æ—¶é—´, seed, è°·æ­Œæœç´¢, **kwargs):
        api_key = APIå¯†é’¥
        base_url = str(APIåœ°å€).rstrip("/")
        model = æ¨¡å‹åç§°
        system_prompt = ç³»ç»Ÿæç¤ºè¯.strip() if isinstance(ç³»ç»Ÿæç¤ºè¯, str) else ""
        user_prompt = éœ€æ±‚æç¤ºè¯.strip() if isinstance(éœ€æ±‚æç¤ºè¯, str) else ""
        seed_value = seed
        prompt = (system_prompt + "\n\n" if system_prompt else "") + user_prompt
        timeout_val = None if int(ç­‰å¾…æ—¶é—´) == 0 else int(ç­‰å¾…æ—¶é—´)

        def extract_error(obj):
            code = None
            message = None
            cur = obj
            for _ in range(3):
                if isinstance(cur, dict):
                    code = cur.get("code") or code
                    message = cur.get("message") if cur.get("message") is not None else message
                    if isinstance(message, str):
                        s = message.strip()
                        if s.startswith("{") and s.endswith("}"):
                            try:
                                cur = json.loads(s)
                                continue
                            except Exception:
                                pass
                    if isinstance(message, dict):
                        cur = message
                        continue
                break
            return code, message

        def raise_if_quota_error(status_code, payload):
            code, message = extract_error(payload)
            if code == "quota_not_enough":
                raise RuntimeError("API é¢åº¦ä¸è¶³ï¼ˆquota_not_enoughï¼‰ï¼Œè¯·å……å€¼æˆ–æ›´æ¢ API Keyã€‚")
            if code == "fail_to_fetch_task":
                inner_code, inner_message = extract_error(message)
                if inner_code == "quota_not_enough":
                    raise RuntimeError("API é¢åº¦ä¸è¶³ï¼ˆquota_not_enoughï¼‰ï¼Œè¯·å……å€¼æˆ–æ›´æ¢ API Keyã€‚")
                if isinstance(inner_message, str) and "quota_not_enough" in inner_message:
                    raise RuntimeError("API é¢åº¦ä¸è¶³ï¼ˆquota_not_enoughï¼‰ï¼Œè¯·å……å€¼æˆ–æ›´æ¢ API Keyã€‚")
            if isinstance(message, str) and "quota_not_enough" in message:
                raise RuntimeError("API é¢åº¦ä¸è¶³ï¼ˆquota_not_enoughï¼‰ï¼Œè¯·å……å€¼æˆ–æ›´æ¢ API Keyã€‚")
            
            # Gemini specific error handling
            if isinstance(payload, dict) and "error" in payload:
                err = payload["error"]
                if isinstance(err, dict):
                     msg = err.get("message", "")
                     if "quota" in msg.lower() or "limit" in msg.lower():
                          print(f"[ComfyUI-shaobkj] Possible quota error: {msg}")

            raise RuntimeError(f"API Error {status_code}: {payload}")

        input_images = []
        for i in range(1, 50):
            img_key = f"image_{i}"
            if img_key in kwargs and kwargs[img_key] is not None:
                input_images.append(kwargs[img_key])
        if "å›¾åƒ" in kwargs and kwargs["å›¾åƒ"] is not None:
            input_images.append(kwargs["å›¾åƒ"])

        if not api_key:
            raise ValueError("API Key is required.")

        if base_url.endswith("/v1"):
            base_url = base_url[:-3]

        url = f"{base_url}/v1beta/models/{model}:generateContent"

        parts = [{"text": prompt}]

        if len(input_images) > 0:
            for img_tensor_batch in input_images:
                batch_size = img_tensor_batch.shape[0]
                for i in range(batch_size):
                    img_tensor = img_tensor_batch[i]
                    if isinstance(img_tensor, torch.Tensor):
                        img_u8 = (img_tensor.clamp(0, 1) * 255).to(torch.uint8).cpu().numpy()
                    else:
                        img_u8 = np.clip(255.0 * np.array(img_tensor), 0, 255).astype(np.uint8)
                    pil_img = Image.fromarray(img_u8)
                    pil_img = resize_pil_long_side(pil_img, é•¿è¾¹è®¾ç½®)

                    buffered = io.BytesIO()
                    pil_img.save(buffered, format="JPEG", quality=85)
                    img_b64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
                    parts.append({"inline_data": {"mime_type": "image/jpeg", "data": img_b64}})

        payload = {"contents": [{"role": "user", "parts": parts}]}
        # å°† seed æ”¾å…¥ generationConfigï¼Œè¿™æ‰æ˜¯ Gemini API çš„æ ‡å‡†åšæ³•
        safe_seed = int(seed_value)
        if safe_seed < 0:
            safe_seed = 0
        if safe_seed > 2147483647:
            safe_seed = safe_seed % 2147483647
        payload["generationConfig"] = {"seed": safe_seed}

        if è°·æ­Œæœç´¢:
            payload["tools"] = [{"googleSearch": {}}]

        headers = {"Content-Type": "application/json", "x-goog-api-key": api_key}

        print(f"[ComfyUI-shaobkj] Sending inference request to {base_url} (Model: {model})...")
        pbar = ProgressBar(100)
        pbar.update_absolute(0)

        disable_insecure_request_warnings()
        session, proxies = create_requests_session(bool(ä½¿ç”¨ç³»ç»Ÿä»£ç†))
        submit_timeout = build_submit_timeout(int(ç­‰å¾…æ—¶é—´))

        try:
            response = post_json_with_retry(
                session,
                url,
                headers=headers,
                payload=payload,
                timeout=submit_timeout,
                proxies=proxies,
                verify=False,
            )

            if response.status_code != 200:
                print(f"[ComfyUI-shaobkj] API Error: {response.status_code}")
                try:
                    err_msg = response.json()
                except Exception:
                    err_msg = response.text
                raise_if_quota_error(response.status_code, err_msg)

            res_json = response.json()
            pbar.update_absolute(60)

            generated_text = ""
            if "candidates" in res_json and len(res_json["candidates"]) > 0:
                candidate = res_json["candidates"][0]
                if "content" in candidate and "parts" in candidate["content"]:
                    for part in candidate["content"]["parts"]:
                        if "text" in part:
                            generated_text += part["text"]

            if not generated_text:
                generated_text = "No text response generated."
            pbar.update_absolute(100)
            api_resp_text = json.dumps(res_json, ensure_ascii=False)
            if not isinstance(api_resp_text, str):
                api_resp_text = str(api_resp_text)
            if len(api_resp_text) > 8000:
                api_resp_text = api_resp_text[:8000] + "...(truncated)"
            return (generated_text, api_resp_text)
        except Exception as e:
            error_msg = f"Error: {str(e)}\n\nTraceback:\n{traceback.format_exc()}"
            print(f"[ComfyUI-shaobkj] Inference Error: {error_msg}")
            raise RuntimeError(f"Inference Failed: {str(e)}") from e

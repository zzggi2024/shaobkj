import json
import re
import io
import base64
import traceback
import torch
import requests
from urllib.parse import urlparse
from server import PromptServer
from .shaobkj_shared import (
    get_config_value,
    post_json_with_retry,
    create_requests_session,
    disable_insecure_request_warnings,
    build_submit_timeout,
    resize_and_encode_image,
    resize_pil_long_side,
    tensor_to_pil
)

class Shaobkj_LLM_App:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(s):
        api_key_default = get_config_value("API_KEY", "SHAOBKJ_API_KEY", "")
        return {
            "required": {
                "APIå¯†é’¥": ("STRING", {"default": api_key_default, "multiline": False, "tooltip": "æœåŠ¡ç«¯ API Keyï¼›æ¨èï¼šå¡«å†™æœ‰æ•ˆ Key"}),
                "APIåœ°å€": ("STRING", {"default": "https://yhmx.work", "multiline": False, "tooltip": "API åŸºç¡€åœ°å€ï¼›æ¨èï¼šhttps://yhmx.work"}),
                "æ¨¡å‹é€‰æ‹©": (["gemini-2.5-flash", "gemini-3-pro-preview"], {"default": "gemini-2.5-flash", "tooltip": "æ¨¡å‹é€‰æ‹©ï¼›æ¨èï¼šgemini-2.5-flash"}),
                "ä½¿ç”¨ç³»ç»Ÿä»£ç†": ("BOOLEAN", {"default": True, "tooltip": "æ˜¯å¦ä½¿ç”¨ç³»ç»Ÿä»£ç†ï¼›æ¨èï¼šå¼€å¯"}),
                "ç³»ç»ŸæŒ‡ä»¤": ("STRING", {"default": "ä½ æ˜¯é«˜æ•ˆçš„AIæç¤ºè¯ç”Ÿæˆå¤§å¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥ç”Ÿæˆå¯ç›´æ¥æ‰§è¡Œçš„æ–¹æ¡ˆæˆ–å†…å®¹ï¼Œç»“æ„æ¸…æ™°ï¼Œç›´æ¥è¾“å‡ºæç¤ºè¯ï¼Œä¸è¦æœ‰ä»»ä½•åºŸè¯ã€‚", "multiline": True, "tooltip": "ç³»ç»Ÿçº§æŒ‡ä»¤ï¼›æ¨èï¼šé»˜è®¤å†…å®¹"}),
                "ç”¨æˆ·è¾“å…¥": ("STRING", {"default": "", "multiline": True, "tooltip": "ç”¨æˆ·è¾“å…¥å†…å®¹ï¼›æ¨èï¼šæ¸…æ™°å…·ä½“"}),
                "æ€è€ƒæ¨¡å¼": ("BOOLEAN", {"default": False, "label_on": "å¼€å¯", "label_off": "å…³é—­", "tooltip": "æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼ï¼›æ¨èï¼šå…³é—­"}),
                "æ€è€ƒé¢„ç®—": ("INT", {"default": 10240, "min": 1024, "max": 65536, "step": 1024, "tooltip": "æ€è€ƒé¢„ç®—ä¸Šé™ï¼›æ¨èï¼š10240"}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 2.0, "step": 0.1, "tooltip": "é‡‡æ ·æ¸©åº¦ï¼›æ¨èï¼š0.7"}),
                "topP": ("FLOAT", {"default": 0.95, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "æ ¸é‡‡æ ·æ¦‚ç‡ï¼›æ¨èï¼š0.95"}),
                "è¾“å…¥å›¾åƒ-é•¿è¾¹è®¾ç½®": (["1024", "1280", "1536"], {"default": "1280", "tooltip": "è¾“å…¥å›¾åƒé•¿è¾¹ç¼©æ”¾ï¼›æ¨èï¼š1280"}),
                "ç­‰å¾…æ—¶é—´": ("INT", {"default": 180, "min": 0, "max": 1000000, "tooltip": "è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)ï¼›æ¨èï¼š180"}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 2147483647, "tooltip": "éšæœºç§å­ï¼›æ¨èï¼š0"}),
                "APIç”³è¯·åœ°å€": ("STRING", {"default": "https://yhmx.work/login?expired=true", "multiline": False, "tooltip": "API ç”³è¯·å…¥å£ï¼›æ¨èï¼šé»˜è®¤åœ°å€"}),
            },
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("æ–‡æœ¬å†…å®¹", "APIå“åº”")
    FUNCTION = "run_llm"
    CATEGORY = "ğŸ¤–shaobkj-APIbox"

    def run_llm(self, APIå¯†é’¥, APIåœ°å€, æ¨¡å‹é€‰æ‹©, ä½¿ç”¨ç³»ç»Ÿä»£ç†, ç³»ç»ŸæŒ‡ä»¤, ç”¨æˆ·è¾“å…¥, æ€è€ƒæ¨¡å¼, æ€è€ƒé¢„ç®—, temperature, topP, è¾“å…¥å›¾åƒ_é•¿è¾¹è®¾ç½®=1280, ç­‰å¾…æ—¶é—´=180, seed=0, **kwargs):
        api_key = APIå¯†é’¥
        if not api_key:
            raise ValueError("API Key is required.")

        base_origin = str(APIåœ°å€).rstrip("/")
        # Remove /v1 suffix if present to avoid duplication if user provides full OpenAI-style base
        if base_origin.endswith("/v1"):
            base_origin = base_origin[:-3]
            
        model = æ¨¡å‹é€‰æ‹©
        long_side_val = int(kwargs.get("è¾“å…¥å›¾åƒ-é•¿è¾¹è®¾ç½®", è¾“å…¥å›¾åƒ_é•¿è¾¹è®¾ç½®))
        image_inputs = []
        for k, v in kwargs.items():
            if k.startswith("image_") and v is not None:
                image_inputs.append((k, v))
        image_inputs.sort(key=lambda x: int(x[0].split("_")[1]))

        def append_images(parts):
            for _, tensor in image_inputs:
                try:
                    if isinstance(tensor, torch.Tensor) and tensor.dim() == 4:
                        for i in range(tensor.shape[0]):
                            pil_img = tensor_to_pil(tensor[i])
                            b64_str, _ = resize_and_encode_image(pil_img, long_side_val)
                            if b64_str:
                                parts.append({"inline_data": {"mime_type": "image/jpeg", "data": b64_str}})
                    else:
                        pil_img = tensor_to_pil(tensor)
                        b64_str, _ = resize_and_encode_image(pil_img, long_side_val)
                        if b64_str:
                            parts.append({"inline_data": {"mime_type": "image/jpeg", "data": b64_str}})
                except Exception:
                    pass

        if model == "gemini-2.5-flash":
            system_prompt = ç³»ç»ŸæŒ‡ä»¤.strip() if isinstance(ç³»ç»ŸæŒ‡ä»¤, str) else ""
            user_prompt = ç”¨æˆ·è¾“å…¥.strip()
            prompt = (system_prompt + "\n\n" if system_prompt else "") + user_prompt
            url = f"{base_origin}/v1beta/models/{model}:generateContent"
            headers = {"Content-Type": "application/json", "x-goog-api-key": api_key}
            parts = [{"text": prompt}]
            append_images(parts)
            payload = {"contents": [{"role": "user", "parts": parts}]}
            safe_seed = int(seed)
            if safe_seed < 0:
                safe_seed = 0
            if safe_seed > 2147483647:
                safe_seed = safe_seed % 2147483647
            payload["generationConfig"] = {"seed": safe_seed}

            def extract_error(obj):
                code = None
                message = None
                cur = obj
                for _ in range(3):
                    if isinstance(cur, dict):
                        code = cur.get("code") or code
                        message = cur.get("message") if cur.get("message") is not None else message
                        if isinstance(message, str):
                            s = message.strip()
                            if s.startswith("{") and s.endswith("}"):
                                try:
                                    cur = json.loads(s)
                                    continue
                                except Exception:
                                    pass
                        if isinstance(message, dict):
                            cur = message
                            continue
                    break
                return code, message

            def raise_if_quota_error(status_code, payload):
                code, message = extract_error(payload)
                if code == "quota_not_enough":
                    raise RuntimeError("API é¢åº¦ä¸è¶³ï¼ˆquota_not_enoughï¼‰ï¼Œè¯·å……å€¼æˆ–æ›´æ¢ API Keyã€‚")
                if code == "fail_to_fetch_task":
                    inner_code, inner_message = extract_error(message)
                    if inner_code == "quota_not_enough":
                        raise RuntimeError("API é¢åº¦ä¸è¶³ï¼ˆquota_not_enoughï¼‰ï¼Œè¯·å……å€¼æˆ–æ›´æ¢ API Keyã€‚")
                    if isinstance(inner_message, str) and "quota_not_enough" in inner_message:
                        raise RuntimeError("API é¢åº¦ä¸è¶³ï¼ˆquota_not_enoughï¼‰ï¼Œè¯·å……å€¼æˆ–æ›´æ¢ API Keyã€‚")
                if isinstance(message, str) and "quota_not_enough" in message:
                    raise RuntimeError("API é¢åº¦ä¸è¶³ï¼ˆquota_not_enoughï¼‰ï¼Œè¯·å……å€¼æˆ–æ›´æ¢ API Keyã€‚")
                if isinstance(payload, dict) and "error" in payload:
                    err = payload["error"]
                    if isinstance(err, dict):
                        msg = err.get("message", "")
                        if "quota" in msg.lower() or "limit" in msg.lower():
                            print(f"[ComfyUI-shaobkj] Possible quota error: {msg}")

            disable_insecure_request_warnings()
            session, proxies = create_requests_session(bool(ä½¿ç”¨ç³»ç»Ÿä»£ç†))
            submit_timeout = build_submit_timeout(int(ç­‰å¾…æ—¶é—´))
            try:
                response = post_json_with_retry(
                    session,
                    url,
                    headers=headers,
                    payload=payload,
                    timeout=submit_timeout,
                    proxies=proxies,
                    verify=False,
                )
                if response.status_code != 200:
                    try:
                        err_msg = response.json()
                    except Exception:
                        err_msg = response.text
                    raise_if_quota_error(response.status_code, err_msg)
                    raise RuntimeError(f"API Error {response.status_code}: {err_msg}")
                try:
                    res_json = response.json()
                except (json.JSONDecodeError, ValueError) as e:
                    raw_text = response.text
                    if not raw_text or not raw_text.strip():
                        raise RuntimeError(f"API Error: Empty response body (HTTP {response.status_code})")
                    raise RuntimeError(f"Invalid JSON response from API: {e}")
                generated_text = ""
                if "candidates" in res_json and len(res_json["candidates"]) > 0:
                    candidate = res_json["candidates"][0]
                    if "content" in candidate and "parts" in candidate["content"]:
                        for part in candidate["content"]["parts"]:
                            if "text" in part:
                                generated_text += part["text"]
                if not generated_text:
                    generated_text = "No text response generated."
                api_resp_text = json.dumps(res_json, ensure_ascii=False)
                if not isinstance(api_resp_text, str):
                    api_resp_text = str(api_resp_text)
                if len(api_resp_text) > 8000:
                    api_resp_text = api_resp_text[:8000] + "...(truncated)"
                return (generated_text, api_resp_text)
            except Exception as e:
                error_msg = f"Error: {str(e)}\n\nTraceback:\n{traceback.format_exc()}"
                print(f"[ComfyUI-shaobkj] Inference Error: {error_msg}")
                return (f"Inference Failed: {str(e)}", error_msg)

        url = f"{base_origin}/v1beta/models/{model}:streamGenerateContent"
        headers = {"Content-Type": "application/json", "x-goog-api-key": api_key}
        payload = {
            "contents": [
                {
                    "role": "user",
                    "parts": [
                        {"text": ç”¨æˆ·è¾“å…¥}
                    ]
                }
            ],
            "generationConfig": {
                "temperature": temperature,
                "topP": topP,
            }
        }
        append_images(payload["contents"][0]["parts"])
        if ç³»ç»ŸæŒ‡ä»¤ and len(ç³»ç»ŸæŒ‡ä»¤.strip()) > 0:
            payload["systemInstruction"] = {"parts": [{"text": ç³»ç»ŸæŒ‡ä»¤}]}
        if æ€è€ƒæ¨¡å¼:
            payload["generationConfig"]["thinkingConfig"] = {
                "includeThoughts": True,
                "thinkingBudget": æ€è€ƒé¢„ç®—
            }
        safe_seed = int(seed)
        if safe_seed < 0:
            safe_seed = 0
        if safe_seed > 2147483647:
            safe_seed = safe_seed % 2147483647
        payload["generationConfig"]["seed"] = safe_seed
        disable_insecure_request_warnings()
        session, proxies = create_requests_session(ä½¿ç”¨ç³»ç»Ÿä»£ç†)
        timeout = build_submit_timeout(ç­‰å¾…æ—¶é—´)
        try:
            response = post_json_with_retry(
                session,
                url,
                headers=headers,
                payload=payload,
                timeout=timeout,
                proxies=proxies,
                max_retries=1
            )
            try:
                data = response.json()
                api_resp_text = json.dumps(data, ensure_ascii=False)
            except Exception:
                text_response = response.text
                data = []
                for line in text_response.splitlines():
                    if line.strip():
                        try:
                            data.append(json.loads(line))
                        except Exception:
                            pass
                api_resp_text = text_response

            full_text = ""

            def extract_text(chunk):
                text = ""
                if "candidates" in chunk:
                    for candidate in chunk["candidates"]:
                        if "content" in candidate and "parts" in candidate["content"]:
                            for part in candidate["content"]["parts"]:
                                if "text" in part:
                                    text += part["text"]
                return text

            if isinstance(data, list):
                for chunk in data:
                    full_text += extract_text(chunk)
            elif isinstance(data, dict):
                full_text = extract_text(data)
            else:
                full_text = str(data)

            if isinstance(full_text, str) and not full_text.strip():
                PromptServer.instance.send_sync(
                    "shaobkj.llm.warning",
                    {"message": "âš ï¸ è¾“å‡ºä¸ºç©ºï¼Œè¯·æ£€æŸ¥è¾“å…¥å†…å®¹æˆ–æ¥å£è¿”å›ã€‚"}
                )
            return (full_text, api_resp_text if isinstance(api_resp_text, str) else str(api_resp_text))
        except Exception as e:
            error_msg = f"LLM Request Failed: {str(e)}"
            print(f"[Shaobkj-LLM] {error_msg}")
            return (error_msg, error_msg)

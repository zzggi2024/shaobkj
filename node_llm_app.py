import json
import re
import requests
from urllib.parse import urlparse
from server import PromptServer
from .shaobkj_shared import (
    get_config_value,
    post_json_with_retry,
    create_requests_session,
    disable_insecure_request_warnings,
    build_submit_timeout,
    resize_and_encode_image,
    tensor_to_pil
)

class Shaobkj_LLM_App:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(s):
        api_key_default = get_config_value("API_KEY", "SHAOBKJ_API_KEY", "")
        return {
            "required": {
                "APIå¯†é’¥": ("STRING", {"default": api_key_default, "multiline": False}),
                "APIåœ°å€": ("STRING", {"default": "https://yhmx.work", "multiline": False}),
                "æ¨¡å‹åç§°": ("STRING", {"default": "gemini-3-pro-preview", "multiline": False}),
                "ä½¿ç”¨ç³»ç»Ÿä»£ç†": ("BOOLEAN", {"default": True}),
                "ç³»ç»ŸæŒ‡ä»¤": ("STRING", {"default": "ä½ æ˜¯é«˜æ•ˆçš„AIæç¤ºè¯ç”Ÿæˆå¤§å¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥ç”Ÿæˆå¯ç›´æ¥æ‰§è¡Œçš„æ–¹æ¡ˆæˆ–å†…å®¹ï¼Œç»“æ„æ¸…æ™°ï¼Œç›´æ¥è¾“å‡ºæç¤ºè¯ï¼Œä¸è¦æœ‰ä»»ä½•åºŸè¯ã€‚", "multiline": True}),
                "ç”¨æˆ·è¾“å…¥": ("STRING", {"default": "", "multiline": True}),
                "æ€è€ƒæ¨¡å¼": ("BOOLEAN", {"default": False, "label_on": "å¼€å¯", "label_off": "å…³é—­"}),
                "æ€è€ƒé¢„ç®—": ("INT", {"default": 10240, "min": 1024, "max": 65536, "step": 1024}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 2.0, "step": 0.1}),
                "topP": ("FLOAT", {"default": 0.95, "min": 0.0, "max": 1.0, "step": 0.01}),
                "è¾“å…¥å›¾åƒ-é•¿è¾¹è®¾ç½®": (["1024", "1280", "1536"], {"default": "1280"}),
                "ç­‰å¾…æ—¶é—´": ("INT", {"default": 180, "min": 0, "max": 1000000, "tooltip": "è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)"}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 2147483647}),
                "APIç”³è¯·åœ°å€": ("STRING", {"default": "https://yhmx.work/login?expired=true", "multiline": False}),
            },
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("æ–‡æœ¬å†…å®¹",)
    FUNCTION = "run_llm"
    CATEGORY = "ğŸ¤–shaobkj-APIbox"

    def run_llm(self, APIå¯†é’¥, APIåœ°å€, æ¨¡å‹åç§°, ä½¿ç”¨ç³»ç»Ÿä»£ç†, ç³»ç»ŸæŒ‡ä»¤, ç”¨æˆ·è¾“å…¥, æ€è€ƒæ¨¡å¼, æ€è€ƒé¢„ç®—, temperature, topP, è¾“å…¥å›¾åƒ_é•¿è¾¹è®¾ç½®=1280, ç­‰å¾…æ—¶é—´=180, seed=0, **kwargs):
        api_key = APIå¯†é’¥
        if not api_key:
            raise ValueError("API Key is required.")

        base_origin = str(APIåœ°å€).rstrip("/")
        # Remove /v1 suffix if present to avoid duplication if user provides full OpenAI-style base
        if base_origin.endswith("/v1"):
            base_origin = base_origin[:-3]
            
        model = æ¨¡å‹åç§°
        
        # Construct URL according to the documentation: 
        # POST /v1beta/models/{model}:streamGenerateContent
        url = f"{base_origin}/v1beta/models/{model}:streamGenerateContent"

        # Headers: Only x-goog-api-key as per project rules to improve proxy compatibility
        headers = {
            "Content-Type": "application/json",
            "x-goog-api-key": api_key
        }

        # Construct Body
        payload = {
            "contents": [
                {
                    "role": "user",
                    "parts": [
                        {"text": ç”¨æˆ·è¾“å…¥}
                    ]
                }
            ],
            "generationConfig": {
                "temperature": temperature,
                "topP": topP,
            }
        }

        long_side_val = int(kwargs.get("è¾“å…¥å›¾åƒ-é•¿è¾¹è®¾ç½®", è¾“å…¥å›¾åƒ_é•¿è¾¹è®¾ç½®))
        image_inputs = []
        for k, v in kwargs.items():
            if k.startswith("image_") and v is not None:
                image_inputs.append((k, v))
        image_inputs.sort(key=lambda x: int(x[0].split("_")[1]))
        for _, tensor in image_inputs:
            try:
                pil_img = tensor_to_pil(tensor)
                b64_str, _ = resize_and_encode_image(pil_img, long_side_val)
                if b64_str:
                    payload["contents"][0]["parts"].append({
                        "inline_data": {
                            "mime_type": "image/jpeg",
                            "data": b64_str
                        }
                    })
            except Exception:
                pass

        # Add system instruction if provided
        if ç³»ç»ŸæŒ‡ä»¤ and len(ç³»ç»ŸæŒ‡ä»¤.strip()) > 0:
            payload["systemInstruction"] = {
                "parts": [
                    {"text": ç³»ç»ŸæŒ‡ä»¤}
                ]
            }

        # Add thinking config if enabled
        if æ€è€ƒæ¨¡å¼:
            payload["generationConfig"]["thinkingConfig"] = {
                "includeThoughts": True,
                "thinkingBudget": æ€è€ƒé¢„ç®—
            }
            
        # Prepare network request
        disable_insecure_request_warnings()
        session, proxies = create_requests_session(ä½¿ç”¨ç³»ç»Ÿä»£ç†)
        
        timeout = build_submit_timeout(ç­‰å¾…æ—¶é—´)
        
        try:
            print(f"[Shaobkj-LLM] Sending request to {url}...")
            response = post_json_with_retry(
                session,
                url,
                headers=headers,
                payload=payload,
                timeout=timeout,
                proxies=proxies,
                max_retries=1
            )
            
            # Parse Response
            # streamGenerateContent returns a list of JSON objects (chunks)
            try:
                data = response.json()
            except Exception:
                # If json() fails, it might be NDJSON or raw text
                text_response = response.text
                # Try to parse as NDJSON
                data = []
                for line in text_response.splitlines():
                    if line.strip():
                        try:
                            data.append(json.loads(line))
                        except Exception:
                            pass
                            
            # Aggregate text from all parts
            full_text = ""
            
            # Helper to extract text from a single chunk
            def extract_text(chunk):
                text = ""
                if "candidates" in chunk:
                    for candidate in chunk["candidates"]:
                        if "content" in candidate and "parts" in candidate["content"]:
                            for part in candidate["content"]["parts"]:
                                if "text" in part:
                                    text += part["text"]
                return text

            if isinstance(data, list):
                for chunk in data:
                    full_text += extract_text(chunk)
            elif isinstance(data, dict):
                full_text = extract_text(data)
            else:
                # Fallback for unexpected format
                full_text = str(data)

            if isinstance(full_text, str) and not full_text.strip():
                PromptServer.instance.send_sync(
                    "shaobkj.llm.warning",
                    {"message": "âš ï¸ è¾“å‡ºä¸ºç©ºï¼Œè¯·æ£€æŸ¥è¾“å…¥å†…å®¹æˆ–æ¥å£è¿”å›ã€‚"}
                )
            return (full_text,)

        except Exception as e:
            error_msg = f"LLM Request Failed: {str(e)}"
            print(f"[Shaobkj-LLM] {error_msg}")
            return (error_msg,)
